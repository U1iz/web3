## 01_神经网络如何工作

[TOC]





### 1.2 一台简单的预测机

> 该算法接收了一个输入，并做出应有的预测后输出结果

如果一个计算机，接收了一个问题，做了一些“思考”，并输出了一个答案

其过程如下：

```
输入 -> 流程（计算） -> 输出
```

例如：

```
输入（3*4） -> 计算（4+4+4） -> 输出（12）
```



#### *千米转化为英里*

<font color="#4343da">现在有一个将 **千米** 转化为 **英里** 的问题</font>

我们知道的其中一个线索是千米跟英里之间存在**线性关系**，所有它的形式应该是

```
英里 = 千米 * C（未知常数）
```

我们拥有的唯一其他线索是，一些正确的**千米/英里匹配的数值**

| 示例 | 千米 | 英里   |
| ---- | ---- | ------ |
| 1    | 0    | 0      |
| 2    | 100  | 62.137 |



为了计算出缺失的常数C，我们将C设为随机数，**取值为0.5**[^1]

```
千米（100） -> 计算（英里 = 千米 * 0.5） -> 英里（50）
```

通过计算 实际值 - 计算值 得出误差**12.137**，*即计算结果距离实际缺少的值*

又因为千米转为英里的公式是线性的，所以我们继续**增加C至0.6**

现在误差为 **2.137**，变得更小了，*这个数值甚至可能是我们很乐于接收的一个误差值*

当我们再次重复这个过程，**将C增至0.7**，误差变为了**-7.863**，已经超过了已知的正确答案。



<font color="#f1aa">*至此，我们可以**结束该流程**，将C取值为0.6，接收误差；也可以**增加精度**，从C=0.61开始继续以上流程，进一步减小误差*</font>



- 改进这些模型的一种好方法是，基于模型和已知真是示例之间的比较，得到模型偏移的误差值，调整参数



[^1]: 更多有趣的问题是没有一个简单的数学公式将输出和输入关联起来的。这就是我们需要诸如神经网络这样相对成熟而复杂的方法原因





### 1.3 分类器与预测器并无太大差别

#### 分类小虫子

<img src="01_神经网络如何工作.assets\image-20230526074952102.png" alt="image-20230526074952102" style="zoom: 32%;" /><font color="#4343da">已知测量得到的花园中小虫子的宽度和长度如图</font>

上个预测器案例可以看作一个 `一元一次方程（y = kx + b）` ，常量C就是斜率K



<img src="01_神经网络如何工作.assets\image-20230526081035340.png" alt="image-20230526081035340" style="zoom:33%;" />因此，在这个分类器案例中，我们可以通过 **调整斜率** 来计算出分界线分类小虫子，如图





数据如下：

| 示例 | 宽度 | 长度 | 小虫 |
| ---- | ---- | ---- | ---- |
| 1    | 3.0  | 1.0  | 瓢虫 |
| 2    | 1.0  | 3.0  | 毛虫 |

公式如下：y = Ax



<img src="01_神经网络如何工作.assets\image-20230526082634169.png" alt="image-20230526082634169" style="zoom:33%;" />我们先给**A取值为0.25**，得出  y = 0.25x，通过作图可以看到该直线未能区分开开两种小虫。

通过计算可以得出，对于**宽度为3.0**的小虫，其**长度为0.75**，小于样本长度1.0，现在可以按照上一个案例，迭代数值趋于样本值

但在该分类器案例中中，该直线自然是应当在瓢虫以上的。即，当宽度X = 3.0时，Y **应当 > 1.0**

因此，我们可以将Y定为较高的 1.1

<img src="01_神经网络如何工作.assets\image-20230526090748360.png" alt="image-20230526090748360" style="zoom:33%;" />

A的初始猜测给了错误的Y值，而Y值应该等于训练数据给定的值（t）

t = (A + ΔA)x[^2]

则误差E 

= t - y 

= (A + ΔA)x - Ax

= **(ΔA)x**



ΔA = E / x

= (1.1 - 0.75) / 3.0

≈ 0.1167



则有关瓢虫的A = (A + ΔA) = 0.3667

*接下来是毛虫的斜率取值*，同上：



当 f(x) = 1.0时

y = 0.3667 * 1.0

与样本中的 y = 3.0 相差甚远

继续计算ΔA = E / x

= (2.9 - 0.3667) / 1.0

= 2.5333



最终的 A = 0.3667 + 2.5333 = 2.9

- <img src="01_神经网络如何工作.assets\image-20230526093848182.png" alt="image-20230526093848182" style="zoom:33%;" />最终的结果如图
- 这种改进方式过于激进，使得最终的直线不会顾及先前的训练样本
- 应该适度改进（moderate）,小心敬慎地向训练样本所指示的方向移动，保持先前训练迭代周期中所得到的值的一部分。
- 当训练数据本身不能确信为完全正确并且包含在现实世界测量中普遍出现的错误或噪声时，有**节制**的调整可以**抑制**这些影响



更改的公式如下

```
ΔA = L(E/x)
```

调节系数通常被称为学习率（learning rate）,因此用“L”表示



我们取L为**0.5**时

瓢虫：

取A = 0.25

f(x) = 3.0时

y = 0.75；t = 1.1；E = t - y = 0..35

ΔA = L(E / x) = 0.5 * (0.35 / 3.0) ≈ 0.0583



A = 0.25 + 0.0583 = 0.3083



毛虫：

f(x) = 1.0时

y = 0.3083；E = 2.9 - 0.3083 = 2.5917

ΔA = L(E / x) = 0.5 * (2.5917 / 1.0) = 1.29585



A = 0.3083 + 1.29585 = 1.60415



<img src="01_神经网络如何工作.assets\image-20230526101004181.png" alt="image-20230526101004181" style="zoom:33%;" />最终得到的分界线如图



[^2]: 数学家使用增量符号“Δ”表示“微小的变化量”





### 1.6 神经元——大自然的计算机器

传统的计算机按照严格的**串行**顺序，相当准确具体地处理数据，**不存在**模糊性或不确定性。

而另一方面，动物的大脑表面看起来以慢得多的节奏运行，却似乎**并行**处理信号，模糊性是其计算的一种特征。

<img src="01_神经网络如何工作.assets\image-20230526153402992.png" alt="image-20230526153402992" style="zoom:33%;" />

虽然神经元有各种形式，但是所有的神经元都是**将电信号从一端传输到另一端**，沿着轴突，将电信号从树突传到树突。

然后，这些信号从一个神经元传递到另一个神经元。

这就是身体感知光、声、触压、热等信号的机制。



- 一般来说，人类大脑有大约 **1000亿** 个神经元。
- 一只果蝇有约 **10万** 个神经元，能够处理许多相当复杂的任务。
- 即便是仅有 **302** 个神经元的线虫，也能完成传统计算机难以完成的任务。



生物的大脑要慢得多，并且比起计算机，其计算元件相对较少

它接收了一个电输入，输出另一个电信号，与之前的案例：预测机&分类机一样，接收输入，将处理结果输出

但神经元与简单的线性函数不同，不能简单地对输入做出的响应生成输出。

因此它的输出**不能**采用这种形式： <u>输出 = （常数 * 输入） + （也行另一常数）</u>



> 观察表明，神经元不会立即反应，而是会抑制输入，直到输入增强，强大到可以触发输出。
>
> 直观上，这是有道理的——神经元不希望传递微小的噪音信号，而只是传递有意识的明显信号。



<img src="01_神经网络如何工作.assets\image-20230526155433220.png" alt="image-20230526155433220" style="zoom:33%;" />在数学上，有许多激活函数可以达到这样的效果，例如 **阶跃函数** 。

*输入达到阈值时，神经元就激发了*



<img src="01_神经网络如何工作.assets\image-20230526161110084.png" alt="image-20230526161110084" style="zoom:33%;" />我们可以改进阶跃函数，如图

该S形函数成为S函数（sigmoid function）[^3]，有时也称为逻辑函数

这个函数相对阶跃函数更加平滑，使其更自然，接近现实。



> 虽然人工智能研究人员还使用其他外形类似的函数，但是S函数简单，并且事实上非常常见
>
> 因此S函数对我们非常重要



其表达式如下

<img src="01_神经网络如何工作.assets\image-20230526161935231.png" alt="image-20230526161935231" style="zoom:67%;" />



其中，**E**为常数**2.71828……**

> 这是个无限不循环小数，这样的数字被称为 超越数（transcendental number）



<img src="01_神经网络如何工作.assets\image-20230526164807614.png" alt="image-20230526164807614" style="zoom:33%;" />

生物神经元可以一次接收多个输入，我们只需对他们进行相加，得到最终总和作为S函数的输入。

> 如果组合信号不够强大，那么S函数的效果是抑制输出信号
>
> 如果总和x足够大，S函数的效果就是激发神经元

如果只有其中一个输入足够大，其它输入都很小，那也足够激发神经元

更重要的是，如果其中一些输入大小一般，但经过组合也能足够大到激发神经元

**因此这些神经元也可以进行一些相对复杂、在某种意义上有点模糊的技术**



> 树突收集了这些电信号，将其组合形成更强的电信号。
>
> 如果信号足够强，超过预知，神经元就会发射信号，沿着轴突，到达终端，将信号传递给下一个神经元的树突
>
> 每个神经元接收来自之前多个神经元的输入，并且如果神经元被激发了，它也同时提供信号给更多神经元。

<img src="01_神经网络如何工作.assets\image-20230526165714525.png" alt="image-20230526165714525" style="zoom: 50%;" />



将这种自然形势复制到人造模型的一种方法是，构建多层的神经元，每一层中的神经元都在与在其前后层的神经元互相连接，如下图。

<img src="01_神经网络如何工作.assets\image-20230526170201551.png" alt="image-20230526170201551" style="zoom: 33%;" />

<img src="01_神经网络如何工作.assets\image-20230527035643628.png" alt="image-20230527035643628" style="zoom:33%;" />如图，标注的w即位该连接的权重



- 这种一致的完全连接形式实际上可以相对容易地编码成计算机指令
- 神经网络的学习过程将会**弱化**这些实际上不需要的连接（即这些连接的权重将趋近于0或者等于0）

因此对于解决特定任务所需要的最小数量的连接冗余几个连接也无伤大雅



> 相比于传统的计算机系统，生物大脑对损坏和不完善具有难以置信的弹性



[^3]: *Sigmoid*函数是一个在生物学中常见的S型函数，也称为S型生长曲线。在信息科学中，由于其单增以及反函数单增等性质常被用作神经网络的激活函数，将变量映射到0,1之间。



### 1.7 在神经网络中追踪信号

<img src="01_神经网络如何工作.assets\image-20230527040415236.png" alt="image-20230527040415236" style="zoom:33%;" />我们使用如图较小的神经网络来演示其工作流程

我们随机取值：

- 两个输入值分别为 **1.0** & **0.5**
- 图中标注的 **w** 为连接权重



> 随机初始值是个不错的注意，这也是我们在先前简单的线性分类器中选择初始斜率值时所做的事情。
>
> 随着分类器学习各个样本，随机值就可以得到改进



<img src="01_神经网络如何工作.assets\image-20230527071330288.png" alt="image-20230527071330288" style="zoom:33%;" />这幅图包括使用链接权重调节输入信号的过程



第一层是输入层，这一层不做其他事情，仅表示输入信号。

*也就是说输入节点**不**对输入值应用激活函数*



接下来的第二层，

我们需要先计算出 **经过权重调节后的组合输入（x）**

x = (1.0 * 0.9) + (0.5 * 0.3)

= 0.9 + 0.15

=1.05

再将该值代入 **S函数** 

y = 1 / (1 + e⁻ˣ)

= 1 / (1 + 1/(2.71828 ** 1.05))

≈ 0.7408

至此我们算出了神经网络中，第一层第二节点的实际输出

第二个节点也是同理

x = (1.0 * 0.2) + (0.5 * 0.8)

= 0.2 + 0.4 = 0.6



y = 1 / (1 + 1/2.71828 ** 0.6)

≈ 0.6457



### 1.8 凭心而论，矩阵乘法大有用途

> 矩阵仅仅是一个数字表格、矩形网格而已。
>
> 对于矩阵而言，没有更多复杂的内容了。



![image-20230527072530856](01_神经网络如何工作.assets\image-20230527072530856.png)

<img src="01_神经网络如何工作.assets\image-20230527073006041.png" alt="image-20230527073006041" style="zoom:33%;" />变量版本的矩阵相乘

> 你不能对两个任意矩阵进行乘法运算，这两个矩阵需要相互兼容
>
> 为了能够进行矩阵相乘，第一个矩阵中的列数目应该等于第二个矩阵中的行数目。

> 在一些书籍中，你会看到这样的矩阵乘法称为点乘（dot product）或内积（inner product）。
>
> 实际上，对于矩阵而言，有不同的乘法，如叉乘，但是我们此处所指的是点乘

![image-20230527073636652](01_神经网络如何工作.assets\image-20230527073636652.png)



如果我们将字母换成对神经网络中的单词，

虽然第二个矩阵是2乘以1的矩阵，但是乘法规则是相同的。

**可以看到，我们可以使用矩阵乘法表示神经网络的所有计算**



我们可以使用以下公式表示

***X* = *W* * *I***

- ***W*** 是权重矩阵
- ***I*** 是输入矩阵
- ***X*** 是组合调节后的信号

> 矩阵通常使用斜体显示，表示它们是矩阵，而不是单个数字



有关激活函数，我们只需对矩阵 ***X*** 每个单独元素应用 **S函数**

因此，来自第二层的最终输出是

***O* = sigmoid( *X* )**

矩阵 ***O***  包含了来自神经网络的最后一层中的所有输出



> 一些计算机编程语言理解举证乘法，使得我们可以更简洁地进行书写

在不同环境中计算出中矩阵方法，详见：<a href="./在不同环境中计算出中矩阵的方法.md?target=file:md" target="_blank">在不同环境中计算出中矩阵的方法.md</a>

